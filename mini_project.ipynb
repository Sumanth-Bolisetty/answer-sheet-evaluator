{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import pytesseract\n",
    "import cv2\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pdf2image import convert_from_path \n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scan the pdf and recognize the text in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(PDF_file,id=\"\"):\n",
    "    pages = convert_from_path(PDF_file, 500, poppler_path=\"C:\\\\Program Files\\\\poppler-21.11.0\\\\Library\\\\bin\")\n",
    "    image_counter = 1\n",
    "    for page in pages:\n",
    "        filename = id+\"_page_\"+str(image_counter)+\".jpg\"\n",
    "        page.save(filename, 'JPEG')\n",
    "        image_counter = image_counter + 1\n",
    "\n",
    "    pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "    out = id+\"_ans.txt\"\n",
    "    f=open(out,\"a\")\n",
    "    for i in range(1, image_counter):\n",
    "        filename = id+\"_page_\"+str(i)+\".jpg\"\n",
    "        img=cv2.imread(filename)\n",
    "        grayscale = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        adaptive =cv2.adaptiveThreshold(grayscale,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,31,9)\n",
    "        text = str(pytesseract.image_to_string(adaptive))\n",
    "        text = text.replace('-\\n', '')\n",
    "        out+=text\n",
    "        f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To break the answer into topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakList(answer):\n",
    "    shead=re.findall(r'[\\n]*[a-zA-Z]+[\\s]*[-]*[a-zA-Z]*:',answer)\n",
    "    heads=[]\n",
    "    for x in shead:\n",
    "        x=x.lstrip(\"\\n\")\n",
    "        heads+=[str(x).replace(':','')]\n",
    "    return answer,heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Lemmattize or stem the words and normalizing the compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized(words):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    words=[lemmatizer.lemmatize(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter the dictionary of paragraphs to the required simple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(para):\n",
    "    para,heads=breakList(para)\n",
    "    words=word_tokenize(para)\n",
    "    headWords=[word.lower() for word in heads.copy()]\n",
    "    words=[word.lower() for word in words.copy()]\n",
    "    words=[str(TextBlob(word).correct()) for word in words.copy()]\n",
    "    headWords=[str(TextBlob(word).correct()) for word in headWords.copy()]\n",
    "    for word in words.copy():\n",
    "        if word in string.punctuation:\n",
    "            words.remove(word)\n",
    "    words=[word for word in words.copy() if word not in stopwords.words() and word.isalnum()]\n",
    "    words=lemmatized(words)\n",
    "    headWords=lemmatized(headWords)\n",
    "    return [words,headWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the percentage of matching in between two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(student, scheme):\n",
    "    k,n,matchPercent=0,0,0\n",
    "    for x in range(2):\n",
    "        for word in scheme[x]:\n",
    "            n+=1\n",
    "            if word in student[x]:\n",
    "                k+=1\n",
    "    matchPercent=(k/n)\n",
    "    return matchPercent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the score based on the weights assigned and correcting the error percentage of the OCR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScore(compulsoryWordsMatch,keyWordsMatch,compulsoryWordsWeight,maxAllotedScore):\n",
    "    score=((compulsoryWordsMatch*compulsoryWordsWeight)+(keyWordsMatch*(100-compulsoryWordsWeight)))*maxAllotedScore/100\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to validate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateQuestion(studentAnswer=\"\", schemeAnswer=\"\", compulsoryWords=\"\", compulsoryWordsWeight=80, maxAllotedScore=10):\n",
    "    keyWords=filter(studentAnswer)\n",
    "    schemeKeyWords=filter(schemeAnswer)\n",
    "    compulsoryWords=filter(compulsoryWords)\n",
    "    \n",
    "    compulsoryWordsMatch=match(keyWords,compulsoryWords)\n",
    "    keyWordsMatch=match(keyWords,schemeKeyWords)\n",
    "    \n",
    "    score=calcScore(compulsoryWordsMatch,keyWordsMatch,compulsoryWordsWeight,maxAllotedScore)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To post the score into the original students dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postScore(studentId,score):\n",
    "    students[studentId].scores[ans]=score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Preprocess the text file to classify the answers one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file):\n",
    "    s=open(file,'r+').read()\n",
    "    ansIds=re.findall(r'[0-9]+\\)',s)\n",
    "    ans=re.split(r'[0-9]+\\)',s)\n",
    "    ans=[x for x in ans.copy() if x!='']\n",
    "    answers=dict()\n",
    "    for n,a in zip(ansIds,ans):\n",
    "        answers[int(n.split(')')[0])]=a\n",
    "    return answers,len(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent data of a student such as his/her answers(dictionary), scores(dictionary) awarded for each question and total score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0lt3s_YolGXm"
   },
   "outputs": [],
   "source": [
    "class student:\n",
    "    def __init__(self,answers,scores,totalScore=0):\n",
    "        self.answers=answers\n",
    "        self.scores=scores\n",
    "        self.totalScore=totalScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking all the details as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To store the data of students with ID as key and student object as value\n",
    "students=dict()\n",
    "n=int(input(\"Enter No. of students: \"))\n",
    "for _ in range(n):\n",
    "    id=input(\"Enter student ID: \")\n",
    "    scan(f\"{id}.pdf\",id)\n",
    "    f=id+\"_ans.txt\"\n",
    "    answers,count=preprocess(f)\n",
    "    scores={}\n",
    "    for i in range(count):\n",
    "        scores[i+1]=0\n",
    "    students[id]=student(answers,scores)\n",
    "\n",
    "#To store the scheme data for each question with Question number as key\n",
    "scan(\"Scheme.pdf\",\"Scheme\")\n",
    "scheme,x=preprocess(\"Scheme_ans.txt\")\n",
    "\n",
    "#To store the compulsory words in answer for each question with Question number as key\n",
    "scan(\"Compulsory.pdf\",\"Compulsory\")\n",
    "compulsoryWords,x=preprocess(\"Compulsory_ans.txt\")\n",
    "\n",
    "#To store the maximum alloted scores for each questions with Question number as key\n",
    "maxAllotedScores=dict()\n",
    "for i in range(count):\n",
    "        maxAllotedScores[i+1]=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate each and every question of each and every student and posting their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in students.keys():\n",
    "    for ans in students[s].answers.keys():\n",
    "        score=validateQuestion(students[s].answers[ans],scheme[ans],compulsoryWords[ans],80,maxAllotedScores[ans])\n",
    "        postScore(s,score)\n",
    "    students[s].totalScore=sum([sc for sc in students[s].scores.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the final scores of each question and total score of each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19131A0531    2 : 9.14    1 : 9.59    18.73\n",
      "19131A0562    1 : 8.50    2 : 9.01    17.51\n"
     ]
    }
   ],
   "source": [
    "for s in students.keys():\n",
    "    print(s,end=\"    \")\n",
    "    for ans in students[s].answers.keys():\n",
    "        print(ans,\":\",\"{:.2f}\".format(students[s].scores[ans]),end=\"    \")\n",
    "    print(\"{:.2f}\".format(students[s].totalScore))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
